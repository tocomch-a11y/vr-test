<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <title>Immediate AR - Stability Max</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://unpkg.com/peerjs@1.3.1/dist/peerjs.min.js"></script>
    <style>
        body { margin: 0; background: #000; overflow: hidden; }
        #overlay { position: absolute; width: 100%; height: 100%; display: flex; flex-direction: column; justify-content: center; align-items: center; background: #000; z-index: 100; }
        button { padding: 30px 60px; font-size: 24px; background: #00ffff; border: none; border-radius: 50px; font-weight: bold; cursor: pointer; }
    </style>
</head>
<body>
    <div id="overlay">
        <button id="arBtn">1. START AR (First)</button>
        <p id="status" style="color:white; font-family:sans-serif; margin-top:20px;">Macからの信号を待機...</p>
    </div>
    <audio id="remoteAudio" autoplay></audio>

    <script type="module">
        let scene, camera, renderer, activeMesh;
        let macData = { low: 0, mid: 0, high: 0, trigger: false };
        let currentIdx = 0, lastSwitch = 0, hueBase = 0;
        const geometries = [];

        // ページ読み込み時に即PeerJSをセットアップ
        const peer = new Peer('psy-link-stable-quest');
        
        peer.on('call', call => {
            call.answer(new MediaStream());
            call.on('stream', stream => {
                document.getElementById('remoteAudio').srcObject = stream;
            });
        });

        peer.on('connection', conn => {
            conn.on('data', data => {
                macData = data; // Macからの解析データ
            });
        });

        document.getElementById('arBtn').onclick = () => startAR();

        async function startAR() {
            // UIを消す
            document.getElementById('overlay').style.display = 'none';

            // 1. Renderer作成
            renderer = new THREE.WebGLRenderer({ antialias: false, alpha: true, powerPreference: "high-performance" });
            renderer.setPixelRatio(1);
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.xr.enabled = true;
            document.body.appendChild(renderer.domElement);

            // 2. Scene / Camera
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(70, window.innerWidth/window.innerHeight, 0.1, 100);
            
            // 3. Geometries
            createGeos();
            activeMesh = new THREE.Mesh(geometries[0], new THREE.MeshBasicMaterial({wireframe: true, transparent: true, opacity: 0.8}));
            scene.add(activeMesh);

            // 4. AR起動（クリックイベントの直後で実行）
            try {
                const session = await navigator.xr.requestSession('immersive-ar', {
                    requiredFeatures: ['local-floor', 'hand-tracking']
                });
                renderer.xr.setSession(session);
                renderer.setAnimationLoop(render);
            } catch (e) {
                console.error("AR開始失敗:", e);
                alert("ARを起動できませんでした。Quest BrowserかつHTTPS環境か確認してください。");
            }
        }

        function createGeos() {
            geometries.push(new THREE.TorusGeometry(5, 0.2, 8, 32));
            geometries.push(new THREE.IcosahedronGeometry(5, 1));
            geometries.push(new THREE.TorusKnotGeometry(4, 1.2, 64, 8));
            geometries.push(new THREE.BoxGeometry(6, 6, 6));
            geometries.push(new THREE.OctahedronGeometry(5, 0));
            geometries.push(new THREE.SphereGeometry(5, 12, 12));
            geometries.push(new THREE.CylinderGeometry(3, 3, 10, 12));
            geometries.push(new THREE.DodecahedronGeometry(5, 0));
            geometries.push(new THREE.TorusGeometry(5, 2, 5, 6));
            geometries.push(new THREE.ConeGeometry(4, 10, 12));
            geometries.push(new THREE.TorusKnotGeometry(4, 0.2, 80, 3));
            geometries.push(new THREE.CapsuleGeometry(3, 6, 2, 12));
        }

        function render(time, frame) {
            hueBase += 0.005;

            // モード切替判定（Mac側からtriggerが来た時だけ）
            if (macData.trigger && Date.now() - lastSwitch > 800) {
                currentIdx = (currentIdx + 1) % 12;
                activeMesh.geometry = geometries[currentIdx];
                lastSwitch = Date.now();
            }

            // ハンドトラッキング（超軽量版）
            let handScale = 0;
            if (frame) {
                const inputSources = frame.session.inputSources;
                for (const input of inputSources) {
                    if (input.hand) {
                        const index = input.hand.get('index-finger-tip');
                        const wrist = input.hand.get('wrist');
                        const pIdx = frame.getJointPose(index, renderer.xr.getReferenceSpace());
                        const pWri = frame.getJointPose(wrist, renderer.xr.getReferenceSpace());
                        if (pIdx && pWri) {
                            const pos = pIdx.transform.position;
                            activeMesh.position.set(pos.x, pos.y, pos.z);
                            // 指の開き具合を計算
                            handScale = Math.hypot(pos.x-pWri.transform.position.x, pos.y-pWri.transform.position.y) * 10;
                        }
                    }
                }
            }

            // 視線の向きを少し加味
            const lookVec = new THREE.Vector3(0,0,-0.5).applyQuaternion(camera.quaternion);
            activeMesh.position.add(lookVec);

            // Mac側の解析データを反映
            const s = 0.5 + (macData.low * 2) + handScale;
            activeMesh.scale.set(s, s, s);
            activeMesh.rotation.y += 0.02 + macData.high * 0.1;
            activeMesh.material.color.setHSL((hueBase + macData.mid)%1, 1, 0.5);

            renderer.render(scene, camera);
        }
    </script>
</body>
</html>
