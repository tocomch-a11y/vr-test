<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <title>Psy-Hand Ultra Light</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://unpkg.com/peerjs@1.3.1/dist/peerjs.min.js"></script>
    <style>
        body { margin: 0; background: #000; overflow: hidden; }
        #overlay { position: absolute; width: 100%; height: 100%; display: flex; flex-direction: column; justify-content: center; align-items: center; color: white; background: #000; z-index: 100; font-family: sans-serif; }
        button { padding: 30px 60px; font-size: 24px; background: #00ffff; border: none; border-radius: 50px; cursor: pointer; font-weight: bold; }
    </style>
</head>
<body>
    <div id="overlay">
        <div id="status">信号を待機中...</div>
        <button id="startBtn" style="display:none;">HAND XR START</button>
    </div>
    <audio id="remoteAudio" autoplay></audio>

    <script type="module">
        let scene, camera, renderer, analyzer, dataL, audioCtx;
        let currentIdx = 0, lastSwitch = 0, hueBase = 0;
        let activeMesh = null;
        const geometries = [];

        // PeerJS Setup
        const peer = new Peer('psy-link-stable-quest');
        peer.on('call', call => {
            call.answer(new MediaStream());
            call.on('stream', stream => {
                document.getElementById('remoteAudio').srcObject = stream;
                document.getElementById('status').innerText = "Link Active";
                document.getElementById('startBtn').style.display = "block";
                window.remoteStream = stream;
            });
        });

        document.getElementById('startBtn').onclick = () => initXR();

        async function initXR() {
            audioCtx = new (window.AudioContext || window.webkitAudioContext)();
            const source = audioCtx.createMediaStreamSource(window.remoteStream);
            analyzer = audioCtx.createAnalyser();
            analyzer.fftSize = 128; // 解析解像度を下げてCPU負荷を激減
            source.connect(analyzer);
            dataL = new Uint8Array(analyzer.frequencyBinCount);
            source.connect(audioCtx.destination);
            
            document.getElementById('overlay').style.display = 'none';

            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(70, window.innerWidth/window.innerHeight, 0.1, 1000);
            renderer = new THREE.WebGLRenderer({ antialias: false, alpha: true, powerPreference: "high-performance" });
            renderer.setPixelRatio(1);
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.xr.enabled = true;
            document.body.appendChild(renderer.domElement);

            // 12種類の幾何学を「メモリ上」だけに作成（シーンには入れない）
            createGeometries();
            
            // 最初のメッシュを設置
            activeMesh = new THREE.Mesh(geometries[0], new THREE.MeshBasicMaterial({wireframe: true, transparent: true}));
            scene.add(activeMesh);

            navigator.xr.requestSession('immersive-ar', { requiredFeatures: ['local-floor', 'hand-tracking'] }).then(s => renderer.xr.setSession(s));
            renderer.setAnimationLoop(render);
        }

        function createGeometries() {
            geometries.push(new THREE.TorusGeometry(10, 0.5, 8, 64));
            geometries.push(new THREE.IcosahedronGeometry(10, 1));
            geometries.push(new THREE.TorusKnotGeometry(8, 2, 64, 8));
            geometries.push(new THREE.BoxGeometry(12, 12, 12));
            geometries.push(new THREE.OctahedronGeometry(10, 0));
            geometries.push(new THREE.SphereGeometry(10, 16, 16));
            geometries.push(new THREE.CylinderGeometry(5, 5, 20, 16, 1, true));
            geometries.push(new THREE.DodecahedronGeometry(10, 0));
            geometries.push(new THREE.TorusGeometry(10, 3, 5, 6));
            geometries.push(new THREE.ConeGeometry(8, 15, 16, 1, true));
            geometries.push(new THREE.TorusKnotGeometry(8, 0.3, 100, 3));
            geometries.push(new THREE.CapsuleGeometry(5, 10, 4, 16));
        }

        function render(time, frame) {
            if (analyzer) {
                analyzer.getByteFrequencyData(dataL);
                const low = dataL[2]/255;
                const high = dataL[20]/255;
                hueBase += 0.005;

                // 低音でモード切替（ジオメトリのすり替えのみ）
                if (low > 0.85 && Date.now() - lastSwitch > 1000) {
                    currentIdx = (currentIdx + 1) % 12;
                    activeMesh.geometry = geometries[currentIdx];
                    lastSwitch = Date.now();
                }

                // ハンドトラッキングの最小限の取得
                let handScale = 1.0;
                let handPos = new THREE.Vector3(0, 0, -20);
                const session = renderer.xr.getSession();
                
                if (session && frame) {
                    const inputSources = session.inputSources;
                    for (const inputSource of inputSources) {
                        if (inputSource.hand) {
                            const indexTip = inputSource.hand.get('index-finger-tip');
                            const wrist = inputSource.hand.get('wrist');
                            const pose = frame.getJointPose(indexTip, renderer.xr.getReferenceSpace());
                            const wPose = frame.getJointPose(wrist, renderer.xr.getReferenceSpace());
                            
                            if (pose && wPose) {
                                // 指と手首の距離でサイズ変化
                                const p1 = pose.transform.position;
                                const p2 = wPose.transform.position;
                                handScale = Math.hypot(p1.x-p2.x, p1.y-p2.y, p1.z-p2.z) * 15;
                                handPos.set(p1.x, p1.y, p1.z);
                            }
                        }
                    }
                }

                // ヘッドトラッキング（向き）の取得
                const lookVec = new THREE.Vector3(0, 0, -1).applyQuaternion(camera.quaternion);

                // ビジュアル更新（負荷の低い数値更新のみ）
                activeMesh.position.lerp(handPos.add(lookVec.multiplyScalar(5)), 0.1);
                activeMesh.scale.setScalar(0.5 + low * 2 + handScale);
                activeMesh.rotation.y += 0.01 + high * 0.1;
                activeMesh.rotation.x += 0.01;
                
                activeMesh.material.color.setHSL((hueBase + handScale*0.1)%1, 1, 0.5);
                activeMesh.material.opacity = 0.2 + low * 0.8;
            }
            renderer.render(scene, camera);
        }
    </script>
</body>
</html>
